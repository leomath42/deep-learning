{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q1tPdd5Jg_HO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-YZir9AOjcWW"
   },
   "source": [
    "# Classificação de clientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "AbAVXrUMiS8I"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# join one or more path components intelligently\n",
    "from os.path import join\n",
    "\n",
    "# Interface com o sistema operacional\n",
    "import os\n",
    "\n",
    "# Manipulação de dataframes\n",
    "import pandas as pd\n",
    "\n",
    "# Manipulação de dados tabulares\n",
    "import numpy as np\n",
    "\n",
    "# Normalização das características\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# visualização de dados baseada no matplotlib\n",
    "import seaborn as sns\n",
    "\n",
    "# Esboço de gráficos\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1q_hJLpdsoML"
   },
   "source": [
    "## Carga e inspeção dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "kqhbdu5V_uCi"
   },
   "outputs": [],
   "source": [
    "# Definição dos nomes das variáveis (conforme a tabela contida no enunciado)\n",
    "colnames = ['ESCT', 'NDEP', 'RENDA', 'TIPOR', 'VBEM', 'NPARC',\n",
    "            'VPARC', 'TEL', 'IDADE', 'RESMS', 'ENTRADA', 'CLASSE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "O8f0yXVbtEmZ"
   },
   "outputs": [],
   "source": [
    "# Leitura dos dados de treino\n",
    "arquivo = './credtrain.txt'\n",
    "data_train = pd.read_csv(arquivo, sep='\\t', header=None, names = colnames)\n",
    "\n",
    "# Leitura dos dados de teste\n",
    "arquivo = './credtest.txt'\n",
    "data_test = pd.read_csv(arquivo, sep='\\t', header=None, names = colnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0tFxQ82et98A"
   },
   "source": [
    "**Inspeção dos dados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Doy7gsSfecpv",
    "outputId": "4470ec1a-7e9d-4065-ce0a-5a2ee1f27750"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(1500, 12) (577, 12)\n"
     ]
    }
   ],
   "source": [
    "# Inspeção da dimensão do dataset\n",
    "print(data_train.shape, data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "1gM-thS-_uCj",
    "outputId": "1501944f-90ae-4431-f01b-fadc35645ff4"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   ESCT  NDEP  RENDA  TIPOR  VBEM  NPARC  VPARC  TEL  IDADE  RESMS  ENTRADA  \\\n",
       "0     1     0    360      0   313      9     52    0     25     48        0   \n",
       "1     0     0    350      1   468     10     65    0     33      6        0   \n",
       "2     0     0   1100      0   829      9    125    0     56     48        0   \n",
       "3     0     0   3000      0   552     12     76    1     31     60        0   \n",
       "4     1     0   1000      0   809     12    111    0     24      7        0   \n",
       "\n",
       "   CLASSE  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ESCT</th>\n      <th>NDEP</th>\n      <th>RENDA</th>\n      <th>TIPOR</th>\n      <th>VBEM</th>\n      <th>NPARC</th>\n      <th>VPARC</th>\n      <th>TEL</th>\n      <th>IDADE</th>\n      <th>RESMS</th>\n      <th>ENTRADA</th>\n      <th>CLASSE</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>360</td>\n      <td>0</td>\n      <td>313</td>\n      <td>9</td>\n      <td>52</td>\n      <td>0</td>\n      <td>25</td>\n      <td>48</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>350</td>\n      <td>1</td>\n      <td>468</td>\n      <td>10</td>\n      <td>65</td>\n      <td>0</td>\n      <td>33</td>\n      <td>6</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1100</td>\n      <td>0</td>\n      <td>829</td>\n      <td>9</td>\n      <td>125</td>\n      <td>0</td>\n      <td>56</td>\n      <td>48</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>3000</td>\n      <td>0</td>\n      <td>552</td>\n      <td>12</td>\n      <td>76</td>\n      <td>1</td>\n      <td>31</td>\n      <td>60</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>0</td>\n      <td>1000</td>\n      <td>0</td>\n      <td>809</td>\n      <td>12</td>\n      <td>111</td>\n      <td>0</td>\n      <td>24</td>\n      <td>7</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "# Inspeção das primeiras linhas do conjunto de treinamento\n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "2qdSwb4AuGEo",
    "outputId": "23030a75-752a-4325-f2ca-6fe8a81d96db"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   ESCT  NDEP  RENDA  TIPOR  VBEM  NPARC  VPARC  TEL  IDADE  RESMS  ENTRADA  \\\n",
       "0     0     2    500      1   618     10     85    0     36      6        0   \n",
       "1     1     0    813      0   552      4    119    0     43     48      119   \n",
       "2     3     0    350      0   488     12     66    0     43      0        0   \n",
       "3     1     0   1530      0   381      1    398    0     28     48        0   \n",
       "4     0     0    688      1   396     10     60    0     49     72        0   \n",
       "\n",
       "   CLASSE  \n",
       "0       0  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ESCT</th>\n      <th>NDEP</th>\n      <th>RENDA</th>\n      <th>TIPOR</th>\n      <th>VBEM</th>\n      <th>NPARC</th>\n      <th>VPARC</th>\n      <th>TEL</th>\n      <th>IDADE</th>\n      <th>RESMS</th>\n      <th>ENTRADA</th>\n      <th>CLASSE</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>2</td>\n      <td>500</td>\n      <td>1</td>\n      <td>618</td>\n      <td>10</td>\n      <td>85</td>\n      <td>0</td>\n      <td>36</td>\n      <td>6</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0</td>\n      <td>813</td>\n      <td>0</td>\n      <td>552</td>\n      <td>4</td>\n      <td>119</td>\n      <td>0</td>\n      <td>43</td>\n      <td>48</td>\n      <td>119</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>0</td>\n      <td>350</td>\n      <td>0</td>\n      <td>488</td>\n      <td>12</td>\n      <td>66</td>\n      <td>0</td>\n      <td>43</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>0</td>\n      <td>1530</td>\n      <td>0</td>\n      <td>381</td>\n      <td>1</td>\n      <td>398</td>\n      <td>0</td>\n      <td>28</td>\n      <td>48</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>688</td>\n      <td>1</td>\n      <td>396</td>\n      <td>10</td>\n      <td>60</td>\n      <td>0</td>\n      <td>49</td>\n      <td>72</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "# Inspeção das primeiras linhas do conjunto de teste\n",
    "data_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6nLoBloCF-sZ"
   },
   "source": [
    "## Pré-processamento dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q-Xss-RY2tml"
   },
   "source": [
    "### Transformação de variáveis não-numéricas\n",
    "\n",
    "É importante observar que a variável ESCT (Estado Civil) é do tipo categórica, podendo assumir 4 valores diferentes (cada valor corresponde a um estado civil). Assim, diferentemente de NDEP (onde cada valor corresponde a uma quantidade de dependentes), na variável ESCT cada valor corresponde a uma categoria. Contudo, este fato pode trazer inconsistências na criação e treinamento de modelos.\n",
    "\n",
    "Para mitigar este problema, uma alternativa é tranformar a variável ESCT em uma variável *dummy* (variável binária). Neste sentido, cada categoria da variável ESCT corresponderá a uma variável. Visto que há 4 possíveis categorias para a variável ESCT, obteremos 4 variáveis ESCT binárias.\n",
    "\n",
    "Uma variável *dummy* é uma variável binária utilizadas para representar categorias. Neste sentido, em um caso de uma variável com 3 ou mais categorias, recomenda-se a criação de $n-1$ dummies. Diante disso, a variável ESCT será transformada em 4 \"variantes dummy\", onde o valor 1 corresponderá à ocorrência de determinada categoria e o valor 0 corresponderá à não ocorrência."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "yErjVPa6_uCo",
    "outputId": "46abe673-8593-43aa-d110-d77311b4fbc1"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   NDEP  RENDA  TIPOR  VBEM  NPARC  VPARC  TEL  IDADE  RESMS  ENTRADA  CLASSE  \\\n",
       "0     0    360      0   313      9     52    0     25     48        0       1   \n",
       "1     0    350      1   468     10     65    0     33      6        0       1   \n",
       "2     0   1100      0   829      9    125    0     56     48        0       1   \n",
       "3     0   3000      0   552     12     76    1     31     60        0       1   \n",
       "4     0   1000      0   809     12    111    0     24      7        0       1   \n",
       "\n",
       "   ESCT_1  ESCT_2  ESCT_3  \n",
       "0       1       0       0  \n",
       "1       0       0       0  \n",
       "2       0       0       0  \n",
       "3       0       0       0  \n",
       "4       1       0       0  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>NDEP</th>\n      <th>RENDA</th>\n      <th>TIPOR</th>\n      <th>VBEM</th>\n      <th>NPARC</th>\n      <th>VPARC</th>\n      <th>TEL</th>\n      <th>IDADE</th>\n      <th>RESMS</th>\n      <th>ENTRADA</th>\n      <th>CLASSE</th>\n      <th>ESCT_1</th>\n      <th>ESCT_2</th>\n      <th>ESCT_3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>360</td>\n      <td>0</td>\n      <td>313</td>\n      <td>9</td>\n      <td>52</td>\n      <td>0</td>\n      <td>25</td>\n      <td>48</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>350</td>\n      <td>1</td>\n      <td>468</td>\n      <td>10</td>\n      <td>65</td>\n      <td>0</td>\n      <td>33</td>\n      <td>6</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>1100</td>\n      <td>0</td>\n      <td>829</td>\n      <td>9</td>\n      <td>125</td>\n      <td>0</td>\n      <td>56</td>\n      <td>48</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>3000</td>\n      <td>0</td>\n      <td>552</td>\n      <td>12</td>\n      <td>76</td>\n      <td>1</td>\n      <td>31</td>\n      <td>60</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>1000</td>\n      <td>0</td>\n      <td>809</td>\n      <td>12</td>\n      <td>111</td>\n      <td>0</td>\n      <td>24</td>\n      <td>7</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "# Aplicação no conjunto de treinamento\n",
    "data_train_new = pd.get_dummies(data = data_train, \n",
    "                                prefix='ESCT', \n",
    "                                columns=['ESCT'], \n",
    "                                drop_first=True)\n",
    "\n",
    "\"\"\"\n",
    "pd.get_dummies: Convert categorical variable into dummy/indicator variables.\n",
    "\"\"\"\n",
    "\n",
    "# Inspeção das primeiras linhas\n",
    "data_train_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "hI9UgoSS_uCp",
    "outputId": "f7f045fd-6660-453a-d4c1-433186b51353"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   NDEP  RENDA  TIPOR  VBEM  NPARC  VPARC  TEL  IDADE  RESMS  ENTRADA  CLASSE  \\\n",
       "0     2    500      1   618     10     85    0     36      6        0       0   \n",
       "1     0    813      0   552      4    119    0     43     48      119       1   \n",
       "2     0    350      0   488     12     66    0     43      0        0       1   \n",
       "3     0   1530      0   381      1    398    0     28     48        0       1   \n",
       "4     0    688      1   396     10     60    0     49     72        0       1   \n",
       "\n",
       "   ESCT_1  ESCT_2  ESCT_3  \n",
       "0       0       0       0  \n",
       "1       1       0       0  \n",
       "2       0       0       1  \n",
       "3       1       0       0  \n",
       "4       0       0       0  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>NDEP</th>\n      <th>RENDA</th>\n      <th>TIPOR</th>\n      <th>VBEM</th>\n      <th>NPARC</th>\n      <th>VPARC</th>\n      <th>TEL</th>\n      <th>IDADE</th>\n      <th>RESMS</th>\n      <th>ENTRADA</th>\n      <th>CLASSE</th>\n      <th>ESCT_1</th>\n      <th>ESCT_2</th>\n      <th>ESCT_3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>500</td>\n      <td>1</td>\n      <td>618</td>\n      <td>10</td>\n      <td>85</td>\n      <td>0</td>\n      <td>36</td>\n      <td>6</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>813</td>\n      <td>0</td>\n      <td>552</td>\n      <td>4</td>\n      <td>119</td>\n      <td>0</td>\n      <td>43</td>\n      <td>48</td>\n      <td>119</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>350</td>\n      <td>0</td>\n      <td>488</td>\n      <td>12</td>\n      <td>66</td>\n      <td>0</td>\n      <td>43</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>1530</td>\n      <td>0</td>\n      <td>381</td>\n      <td>1</td>\n      <td>398</td>\n      <td>0</td>\n      <td>28</td>\n      <td>48</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>688</td>\n      <td>1</td>\n      <td>396</td>\n      <td>10</td>\n      <td>60</td>\n      <td>0</td>\n      <td>49</td>\n      <td>72</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "# Aplicação da transformação sobre o conjunto de teste\n",
    "data_test_new = pd.get_dummies(data = data_test, prefix='ESCT', columns=['ESCT'], drop_first=True)\n",
    "\n",
    "\"\"\"\n",
    "pd.get_dummies: Convert categorical variable into dummy/indicator variables\n",
    "\"\"\"\n",
    "\n",
    "# Inspeção das primeiras linhas\n",
    "data_test_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yRkwEDzO91ZB"
   },
   "source": [
    "**Separação do conjunto de dados em rótulo ($\\mathrm{y}$) e features ($\\mathrm{x}$)**\n",
    "\n",
    "O rótulo ($\\mathrm{y}$) corresponde ao vetor contendo a variável alvo (CLASSE), enquanto que features ($\\mathrm{x}$) corresponde à matriz de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mxKjqguU_uCr",
    "outputId": "c3dbcdc2-f51d-4e21-9a53-3832d6772ae2"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1])"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "# Transformação da variável alvo do conjunto de treinamento em vetor\n",
    "y_train = np.array(data_train_new['CLASSE'])\n",
    "\n",
    "# Inspeção das primeira linhas\n",
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9bIZH23c_uCt",
    "outputId": "d94dc393-5b9a-45d1-cb03-8ee573380f56"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1, 1])"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "# Transformação da variável alvo do conjunto de teste em vetor\n",
    "y_test = np.array(data_test_new['CLASSE'])\n",
    "\n",
    "# Inspeção das primeiras linhas\n",
    "y_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J7YkPky3_uCv",
    "outputId": "0ae3183e-a089-476c-e3fc-ca778054cddf"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[   0,  360,    0, ...,    1,    0,    0],\n",
       "       [   0,  350,    1, ...,    0,    0,    0],\n",
       "       [   0, 1100,    0, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [   0,  570,    0, ...,    0,    0,    0],\n",
       "       [   0,  360,    0, ...,    0,    0,    0],\n",
       "       [   4,  501,    1, ...,    0,    0,    0]])"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "# Transformação do conjunto de treinamento remanescente em matriz de dados\n",
    "features_name_train = list(data_train_new.columns)               # nomes das colunas\n",
    "features_name_train.remove('CLASSE')                             # remove variável \"CLASSE\"\n",
    "X_train = np.array(data_train_new.loc[:, features_name_train])   # Transformação em matriz de dados\n",
    "\n",
    "# Inspeção da matriz resultante\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zl5JbSo2_uCw",
    "outputId": "2f5df1c3-67df-4af4-f536-524f9912dd15"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[   2,  500,    1, ...,    0,    0,    0],\n",
       "       [   0,  813,    0, ...,    1,    0,    0],\n",
       "       [   0,  350,    0, ...,    0,    0,    1],\n",
       "       ...,\n",
       "       [   3, 1200,    0, ...,    0,    0,    0],\n",
       "       [   0,  600,    0, ...,    1,    0,    0],\n",
       "       [   0,  800,    1, ...,    0,    0,    0]])"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "# Transformação do conjunto de teste remanescente em matriz de dados\n",
    "features_name_test = list(data_test_new.columns)               # Recuperação dos nomes das colunas\n",
    "features_name_test.remove('CLASSE')                            # Remoção da variável \"CLASSE\"\n",
    "X_test = np.array(data_test_new.loc[:, features_name_test])   # Transformação em matriz\n",
    "\n",
    "# Inspeção da matriz resultante\n",
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rd9a5XDvDmso"
   },
   "source": [
    "### Normalização das features\n",
    "\n",
    "Antes de iniciar o treinamento, é também necessário realizar a *normalização* das características a fim de evitar problemas decorrentes à discrepância nas ordens de grandeza das features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "CNkkpj63EedQ"
   },
   "outputs": [],
   "source": [
    "# Criação do objeto para a padronização das features\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Ajustamento do StandardScaler ao conjunto de dados de treino e padronização dos dados de treino\n",
    "X_train_norm = scaler.fit_transform(X_train)\n",
    "\n",
    "# Transformação dos dados de teste com os parâmetros ajustados a partir dos dados de treino\n",
    "X_test_norm = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RazjkSXbe336",
    "outputId": "b6c38010-45cd-4e4a-fc87-1142aa5c61c0"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(1500, 13) (577, 13) (1500,) (577,)\n"
     ]
    }
   ],
   "source": [
    "# Dimensões dos datasets\n",
    "print(X_train_norm.shape, X_test_norm.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XIe5k4w4kA-B"
   },
   "source": [
    "## Treinamento do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "7GWUb_d4kJI8",
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "x: torch.Size([50, 13])\ny: torch.Size([50])\ny2: torch.Size([50, 1])\n\ntorch.Size([13, 1])\ntensor([[ -0.7101],\n        [ -7.7911],\n        [-10.9885],\n        [ -2.9503],\n        [  6.5243],\n        [ -5.1885],\n        [  4.2683],\n        [-10.5322],\n        [  2.4116],\n        [ -4.9095],\n        [ -3.2909],\n        [ -2.6205],\n        [  3.4256]])\n"
     ]
    }
   ],
   "source": [
    "# seu código aqui\n",
    "\n",
    "# transformando numpy arrays em  Tensores do Pytorch\n",
    "# Convertendo os datsets de treino e de tests.:\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as torch_functions\n",
    "\n",
    "# Define loss function\n",
    "mse_loss = torch_functions.mse_loss\n",
    "bce_loss = torch_functions.binary_cross_entropy \n",
    "\n",
    "# Definindo algumas constantes\n",
    "BATCH_SIZE = 50\n",
    "LEARNING_RATE = 1e-5\n",
    "NUM_EPOCHS = 1\n",
    "\n",
    "# como o dtype dos inputs e outputs são diferentes, precisamos convertelos\n",
    "# para um tipo único, convertendo então para float32\n",
    "# dataset de treino # print(y_train_tensor.dtype)\n",
    "X_train_tensor = torch.from_numpy(X_train_norm).float()\n",
    "y_train_tensor = torch.from_numpy(y_train).float()\n",
    "\n",
    "# dataset de testes\n",
    "X_test_tensor = torch.from_numpy(X_test_norm).float()\n",
    "y_test_tensor = torch.from_numpy(y_test).float()\n",
    "\n",
    "\n",
    "# Definindo objetos tensores de dataset e o dataloader para o conj. de dados\n",
    "# de treino e de testes.\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_dataset_loader = DataLoader(train_dataset, BATCH_SIZE, shuffle=True)\n",
    "\n",
    "\n",
    "test_dataset        = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "test_dataset_loader = DataLoader(test_dataset, BATCH_SIZE)\n",
    "\n",
    "# imprime algumas informações importantes na tela\n",
    "\n",
    "for x, y in train_dataset_loader:\n",
    "    print('x: {}'.format(x.shape))\n",
    "    print('y: {}'.format(y.shape))\n",
    "    y2 = y.unsqueeze(1)\n",
    "    print('y2: {}'.format(y2.shape))\n",
    "    print('')\n",
    "    # print('x: {0}\\ny: {1}'.format(x,y))\n",
    "    value =  x.T.matmul(y2)\n",
    "    print(value.shape)\n",
    "    print(value)\n",
    "    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.float32\ntorch.float32\n"
     ]
    }
   ],
   "source": [
    "print(X_train_tensor.float().dtype)\n",
    "print(y_train_tensor.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "13\n1500\n"
     ]
    }
   ],
   "source": [
    "# Definindo um modelo para o problema:\n",
    "import torch.nn as nn\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, output_size, f_loss):\n",
    "        super().__init__()\n",
    "        self.f_loss = f_loss\n",
    "        self.hidden_layer = nn.Linear(input_size, hidden_size)\n",
    "\n",
    "        self.output_layer = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "\n",
    "    def forward(self, _input):\n",
    "        hidden_output = self.hidden_layer(_input)\n",
    "        # Usando a função de ativação da camada oculta\n",
    "        out = torch_functions.relu(hidden_output)\n",
    "        # camada de saída\n",
    "        out = self.output_layer(out)\n",
    "\n",
    "        out = torch_functions.sigmoid(out)\n",
    "        return out\n",
    "    \n",
    "    def training_step(self, x, y):\n",
    "        output = self(x)\n",
    "        loss = self.f_loss(output, y)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def evaluate(self, validation_batch):\n",
    "        # outputs = [self.validation_step(x) for x in validation_batch]\n",
    "        loss = []\n",
    "        accuracy = []\n",
    "        for x, y in validation_batch:\n",
    "            kw = self.validation_step(x, y)\n",
    "            loss.append(kw.get('loss'))\n",
    "            accuracy.append(kw.get('accuracy'))\n",
    "\n",
    "        \n",
    "        return {\n",
    "            'loss': np.array(loss).mean(),\n",
    "            'accuracy': np.array(accuracy).mean()\n",
    "        }\n",
    "\n",
    "    def accuracy(self, x, y): # x, y batch\n",
    "        print('--------------------')\n",
    "        print('x {0} y {1}'.format(x.shape, y.shape))\n",
    "        _, preds = torch.max(x, dim=1)\n",
    "        print('_ {0} preds {1}'.format(_, preds))\n",
    "        value = torch.tensor(torch.sum(preds == y).item() / len(preds))\n",
    "        print('value {}'.format(value))\n",
    "\n",
    "    def validation_step(self, x, y): # x, y batch\n",
    "        output = self(x)\n",
    "        loss = self.f_loss(output, y)\n",
    "        _accuracy = self.accuracy(output, y)\n",
    "\n",
    "        return {'loss':loss.item(), 'accuracy': _accuracy.item()}\n",
    "\n",
    "\n",
    "\n",
    "# # Primeira camada de neurônios da rede:\n",
    "# layer_model_1 = torch.nn.Linear(13, 4)\n",
    "# # print(X_train_tensor.shape[1])\n",
    "# # print(y_train_tensor.shape[0])\n",
    "# loss = mse_loss(layer_model_1(X_train_tensor[0:4]), y_train_tensor[0:4])\n",
    "# print(loss.item())\n",
    "\n",
    "input_size = X_train_tensor.shape[1]\n",
    "print(input_size)\n",
    "hidden_size = BATCH_SIZE\n",
    "output_size = y_train_tensor.shape[0]\n",
    "print(output_size)\n",
    "model = Model(13, 50, 1, mse_loss)\n",
    "# loss_1 = mse_loss(model(X_train_tensor), y_train_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "only one element tensors can be converted to Python scalars",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [72]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m np\u001b[38;5;241m.\u001b[39marray([torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m1.\u001b[39m,\u001b[38;5;241m2.\u001b[39m])\u001b[38;5;241m.\u001b[39mnumpy(), torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m3.\u001b[39m,\u001b[38;5;241m4.\u001b[39m])\u001b[38;5;241m.\u001b[39mnumpy()])\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m      5\u001b[0m tl \u001b[38;5;241m=\u001b[39m [torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m1.\u001b[39m,\u001b[38;5;241m2.\u001b[39m])]\n\u001b[0;32m----> 6\u001b[0m tl \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m torch\u001b[38;5;241m.\u001b[39mstack(tl)\n",
      "\u001b[0;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "\n",
    "np.array([torch.tensor([1.,2.]).numpy(), torch.tensor([3.,4.]).numpy()]).mean()\n",
    "\n",
    "tl = [torch.tensor([1.,2.]), torch.tensor([3.,4.])]\n",
    "tl = torch.tensor(tl)\n",
    "torch.stack(tl)\n",
    "# torch.mean(tl)\n",
    "# t = torch.tensor([1.,2.])\n",
    "# t.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--------------------\nx torch.Size([50, 1]) y torch.Size([50])\n_ tensor([0.3954, 0.4230, 0.4749, 0.4558, 0.4326, 0.4094, 0.4051, 0.4388, 0.4071,\n        0.3987, 0.4308, 0.4672, 0.4328, 0.4214, 0.4399, 0.3960, 0.4150, 0.3744,\n        0.4409, 0.4406, 0.4453, 0.4160, 0.4652, 0.4559, 0.4126, 0.4140, 0.3742,\n        0.4544, 0.4207, 0.4355, 0.4388, 0.3744, 0.4463, 0.4024, 0.4307, 0.4366,\n        0.4382, 0.4097, 0.4470, 0.3753, 0.4279, 0.4163, 0.4446, 0.4653, 0.4089,\n        0.4081, 0.3614, 0.4136, 0.4342, 0.4411], grad_fn=<MaxBackward0>) preds tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0])\nvalue 0.5600000023841858\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'item'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [79]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[38;5;66;03m# print('Epoch [{}/{}], Loss: {:.4f}'.\\\u001b[39;00m\n\u001b[1;32m     26\u001b[0m         \u001b[38;5;66;03m#             format(epoch+1, NUM_EPOCHS, loss.item())\u001b[39;00m\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;66;03m#             )\u001b[39;00m\n\u001b[1;32m     28\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch [\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m], val_loss: \u001b[39m\u001b[38;5;132;01m{:.4f}\u001b[39;00m\u001b[38;5;124m, val_acc: \u001b[39m\u001b[38;5;132;01m{:.4f}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(epoch, result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m], result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[0;32m---> 30\u001b[0m \u001b[43mtraning_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNUM_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mLEARNING_RATE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataset_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dataset_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [79]\u001b[0m, in \u001b[0;36mtraning_model\u001b[0;34m(model, epochs, learning_rate, train_loader, validation_loader, opt_func)\u001b[0m\n\u001b[1;32m     14\u001b[0m     opt\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;66;03m# Print the progress\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;66;03m# if (epoch+1) % 10 == 0:\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;66;03m#     print('Epoch [{}/{}], Loss: {:.4f}'.\\\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m \n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# validation\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalidation_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# print('Epoch [{}/{}], Loss: {:.4f}'.\\\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m#             format(epoch+1, NUM_EPOCHS, loss.item())\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m#             )\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch [\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m], val_loss: \u001b[39m\u001b[38;5;132;01m{:.4f}\u001b[39;00m\u001b[38;5;124m, val_acc: \u001b[39m\u001b[38;5;132;01m{:.4f}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(epoch, result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m], result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n",
      "Input \u001b[0;32mIn [78]\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[0;34m(self, validation_batch)\u001b[0m\n\u001b[1;32m     33\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;129;01min\u001b[39;00m validation_batch:\n\u001b[0;32m---> 35\u001b[0m     kw \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidation_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m     loss\u001b[38;5;241m.\u001b[39mappend(kw\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     37\u001b[0m     accuracy\u001b[38;5;241m.\u001b[39mappend(kw\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "Input \u001b[0;32mIn [78]\u001b[0m, in \u001b[0;36mModel.validation_step\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m     55\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_loss(output, y)\n\u001b[1;32m     56\u001b[0m _accuracy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccuracy(output, y)\n\u001b[0;32m---> 58\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m:loss\u001b[38;5;241m.\u001b[39mitem(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43m_accuracy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m()}\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'item'"
     ]
    }
   ],
   "source": [
    "\n",
    "NUM_EPOCHS = 1\n",
    "\n",
    "def traning_model(model, epochs, learning_rate, train_loader, validation_loader, opt_func=torch.optim.SGD):\n",
    "    opt = opt_func(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for x, y in train_dataset_loader:\n",
    "            loss = model.training_step(x, y)\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            opt.step()\n",
    "\n",
    "            opt.zero_grad()\n",
    "\n",
    "            # Print the progress\n",
    "            # if (epoch+1) % 10 == 0:\n",
    "            #     print('Epoch [{}/{}], Loss: {:.4f}'.\\\n",
    "            #         format(epoch+1, NUM_EPOCHS, loss.item())\n",
    "            #         )\n",
    "        \n",
    "        # validation\n",
    "\n",
    "        result = model.evaluate(validation_loader)\n",
    "        # print('Epoch [{}/{}], Loss: {:.4f}'.\\\n",
    "        #             format(epoch+1, NUM_EPOCHS, loss.item())\n",
    "        #             )\n",
    "        print(\"Epoch [{}], val_loss: {:.4f}, val_acc: {:.4f}\".format(epoch, result['loss'], result['accuracy']))\n",
    "\n",
    "traning_model(model, NUM_EPOCHS, LEARNING_RATE, train_dataset_loader, test_dataset_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "mse_loss :\ntensor(0.2517, grad_fn=<MseLossBackward0>)\ntensor(0.2514, grad_fn=<MseLossBackward0>)\nbce_loss :\ntensor(0.6779, grad_fn=<BinaryCrossEntropyBackward0>)\ntensor(0.6781, grad_fn=<BinaryCrossEntropyBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Verificando a loss antes do treino para efeito de comparativo:\n",
    "print('mse_loss :')\n",
    "\n",
    "loss = mse_loss(model(X_train_tensor), y_train_tensor)\n",
    "print(loss)\n",
    "\n",
    "loss = mse_loss(model(X_test_tensor), y_test_tensor)\n",
    "print(loss)\n",
    "\n",
    "print('bce_loss :')\n",
    "\n",
    "loss = bce_loss(model(X_train_tensor), y_train_tensor.unsqueeze(1))\n",
    "print(loss)\n",
    "\n",
    "loss = bce_loss(model(X_test_tensor), y_test_tensor.unsqueeze(1))\n",
    "print(loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5T9JwxRikHKh"
   },
   "source": [
    "## Validação do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "2j8gkXUQkLY8"
   },
   "outputs": [],
   "source": [
    "# seu código aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Niw6wHrljjV2"
   },
   "source": [
    " # Predição de preços de diamantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ONbiiXLbq1tA"
   },
   "source": [
    "## Carga e inspeção dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "LmBHvO2Cq08F"
   },
   "outputs": [],
   "source": [
    "# seu código aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iEp9JWGCqMkm"
   },
   "source": [
    "## Pré-processamento dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "9t7KmrCakSpa"
   },
   "outputs": [],
   "source": [
    "# seu código aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XIQ-Z9WtqOtt"
   },
   "source": [
    "## Treinamento do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "z32YFTSrqTX5"
   },
   "outputs": [],
   "source": [
    "# seu código aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e5p1O5qXqYf0"
   },
   "source": [
    "## Validação do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "b626XbseqYf0"
   },
   "outputs": [],
   "source": [
    "# seu código aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JY79wPKJjn6j"
   },
   "source": [
    "# Classificação de imagens (Fashion MNIST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x9DDmWNDrEJj"
   },
   "source": [
    "## Carga e inspeção dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "CFZiP_KYrEJj"
   },
   "outputs": [],
   "source": [
    "# seu código aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G9vwj6JLrEJj"
   },
   "source": [
    "## Pré-processamento dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "a9eg0TLyrEJk"
   },
   "outputs": [],
   "source": [
    "# seu código aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PD4E55alrEJk"
   },
   "source": [
    "## Treinamento do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "hNJlO8TvrEJk"
   },
   "outputs": [],
   "source": [
    "# seu código aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fm6UfQL7rEJk"
   },
   "source": [
    "## Validação do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "-ehrIzAxkTgJ"
   },
   "outputs": [],
   "source": [
    "# seu código aqui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DL_T1.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}